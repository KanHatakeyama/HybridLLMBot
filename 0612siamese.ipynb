{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリを自動リロード\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "q_a_dict_path=\"develop/q_a_dict.bin\"\n",
    "text_dict=joblib.load(q_a_dict_path)\n",
    "qa_df=pd.read_csv(\"develop/q_and_a_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_to_a_dict={}\n",
    "for i in range(len(qa_df)):\n",
    "    q=qa_df[\"Q\"][i]\n",
    "    a=qa_df[\"A\"][i]\n",
    "    q_to_a_dict[q]=a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "q_list=list(qa_df[\"Q\"])\n",
    "a_list=list(qa_df[\"A\"])\n",
    "\n",
    "q_a_dataset=[]\n",
    "for q in q_list:\n",
    "    q_a_dataset.append((q,q_to_a_dict[q],1))\n",
    "\n",
    "\n",
    "for i in range(len(q_list)*1):\n",
    "    q=random.choice(q_list)\n",
    "    a=random.choice(a_list)\n",
    "    if q_to_a_dict[q]!=a:\n",
    "        q_a_dataset.append((q,a,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "data1=[]\n",
    "data2=[]\n",
    "label_list=[]\n",
    "dataset_list=[]\n",
    "for data in q_a_dataset:\n",
    "    q=data[0]\n",
    "    a=data[1]\n",
    "    label=data[2]\n",
    "    #v_q=text_dict[q].reshape(-1)\n",
    "    #v_a=text_dict[a].reshape(-1)\n",
    "    #data1.append(v_q)\n",
    "    #data2.append(v_a)\n",
    "    data1.append(q)\n",
    "    data2.append(a)\n",
    "    label_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMSearch.Siamese.DictEmbedder import DictEmbedder\n",
    "from LLMSearch.Embedding.GPTEmbedding import GPTEmbedding\n",
    "from settings.key import GPT_API_KEY\n",
    "gpt_embedder=GPTEmbedding(GPT_API_KEY)\n",
    "embedder=DictEmbedder(q_a_dict_path,gpt_embedder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                | Params\n",
      "-----------------------------------------------------\n",
      "0 | base_network | BaseNetwork         | 25.1 K\n",
      "1 | loss         | CosineEmbeddingLoss | 0     \n",
      "-----------------------------------------------------\n",
      "25.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.1 K    Total params\n",
      "0.101     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de392d59e8c74c7d96fd1775d3bb9613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a637bc044d334d50a7d9a467841a74dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0617740eadfe46c6849f8c6ed9814520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3017d7f095412cbfa0c0c426e77cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d690ea1690804d9386db3dc420be26d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d831f1c836df4f73a4ef85eca53e1916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87d99531df5499382919457336cfd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3fd0196cab4c8a8ba33aa35b620c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3870eb10814dacb9fedf7cd102b8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999d9e3f37eb47d8b95636f9e4eb24e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6317d2b2131248fc9ab2833b4fba9ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33614fad5914709b191269b4b6bd6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7457982d2d42d480d1001b1a83d1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LLMSearch.Siamese.SiameseComparer import SiameseComparer\n",
    "comparer=SiameseComparer(embedder)\n",
    "comparer.prepare_model(data1,data2,label_list,hidden_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999998 , 0.8280061 , 0.5429986 , 0.8624289 , 0.76487887,\n",
       "       0.62774307], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_q=\"私は猫が好きです\"\n",
    "answers=[\"私は猫が好きです\",\"猫は好きですか\",a,\"詩人の趣味は?\",\"this is a pen\",\"彼は怒っている\"]\n",
    "\n",
    "comparer.compare(\n",
    "    [target_q]*len(answers),\n",
    "    answers\n",
    "\n",
    "                  )\n",
    "#comparer.compare(q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008620689655172414"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
