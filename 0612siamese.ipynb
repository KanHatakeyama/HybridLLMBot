{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "q_a_dict_path=\"develop/q_a_dict.bin\"\n",
    "text_dict=joblib.load(q_a_dict_path)\n",
    "qa_df=pd.read_csv(\"develop/q_and_a_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_to_a_dict={}\n",
    "for i in range(len(qa_df)):\n",
    "    q=qa_df[\"Q\"][i]\n",
    "    a=qa_df[\"A\"][i]\n",
    "    q_to_a_dict[q]=a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "q_list=list(qa_df[\"Q\"])\n",
    "a_list=list(qa_df[\"A\"])\n",
    "\n",
    "q_a_dataset=[]\n",
    "for q in q_list:\n",
    "    q_a_dataset.append((q,q_to_a_dict[q],1))\n",
    "\n",
    "\n",
    "for i in range(len(q_list)*10):\n",
    "    q=random.choice(q_list)\n",
    "    a=random.choice(a_list)\n",
    "    if q_to_a_dict[q]!=a:\n",
    "        q_a_dataset.append((q,a,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "data1=[]\n",
    "data2=[]\n",
    "label_list=[]\n",
    "dataset_list=[]\n",
    "for data in q_a_dataset:\n",
    "    q=data[0]\n",
    "    a=data[1]\n",
    "    label=data[2]\n",
    "    v_q=text_dict[q].reshape(-1)\n",
    "    v_a=text_dict[a].reshape(-1)\n",
    "    data1.append(v_q)\n",
    "    data2.append(v_a)\n",
    "    label_list.append(label)\n",
    "    dataset_list.append((v_q,v_a,label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data1=torch.tensor(data1)\n",
    "data2=torch.tensor(data2)\n",
    "labels=torch.tensor(label_list)\n",
    "\n",
    "#data1,data2,labelsのランダムな90%を学習用、10%を検証用にする\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data1,valid_data1,train_data2,valid_data2,train_labels,valid_labels=train_test_split(data1,data2,labels,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# ベースとなるネットワークを定義\n",
    "class BaseNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=64, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.layer3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        #x = (self.layer2(x))\n",
    "        x = (self.layer3(x))\n",
    "        return x\n",
    "\n",
    "# Siamese Networkを定義\n",
    "class SiameseNetwork(pl.LightningModule):\n",
    "    def __init__(self, input_dim=64, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.base_network = BaseNetwork(input_dim, hidden_dim)\n",
    "        self.loss = nn.CosineEmbeddingLoss()\n",
    "\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.base_network(input1)\n",
    "        output2 = self.base_network(input2)\n",
    "        return output1, output2\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input1, input2, labels = batch\n",
    "        output1, output2 = self.forward(input1, input2)\n",
    "        loss = self.loss(output1, output2, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input1, input2, labels = batch\n",
    "        output1, output2 = self.forward(input1, input2)\n",
    "        loss = self.loss(output1, output2, labels)\n",
    "        self.log('val_loss', loss)\n",
    "        #print(\"val_loss:\",loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                | Params\n",
      "-----------------------------------------------------\n",
      "0 | base_network | BaseNetwork         | 525 K \n",
      "1 | loss         | CosineEmbeddingLoss | 0     \n",
      "-----------------------------------------------------\n",
      "525 K     Trainable params\n",
      "0         Non-trainable params\n",
      "525 K     Total params\n",
      "2.100     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c2781193da4ace8ff8fbd3bd0073f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a591661d1954e069f01a9984eb7e47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1205d77c1643dba918a2be90298dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0659368e40f54f439f5ebecc880598de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0658a9e4ae554e82aee898138c400d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5be913632b47b9803b4253aef9353d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c07716b7b7e4567ad083b389294eb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a8f1f3be7b453fa395d6e05e2e0b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0986fabf0bc4a82b03d23a7d596147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790d57114c3042cba892a5271192a101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ca62ebd19a4701bc92eb2a6c3b772d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a855a07389841839f5f7a23d081aeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de12a7c4095f4f1b973b02ea5278b100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "train_dataset = torch.utils.data.TensorDataset(train_data1, train_data2, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "val_dataset = torch.utils.data.TensorDataset(valid_data1, valid_data2, valid_labels)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "model = SiameseNetwork(input_dim=1536,hidden_dim=256)\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss')\n",
    "trainer = pl.Trainer(max_epochs=100, callbacks=[early_stop_callback])\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>-0.005396</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.006762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.009541</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-0.006052</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.008067</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.009267</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.154928</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.209650</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>-0.006007</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1\n",
       "0   -0.008118  1.0\n",
       "429 -0.005396  1.0\n",
       "350 -0.006762  1.0\n",
       "121 -0.009541  1.0\n",
       "109 -0.006052  1.0\n",
       "..        ...  ...\n",
       "163 -0.008067 -1.0\n",
       "161 -0.009267 -1.0\n",
       "160 -0.154928 -1.0\n",
       "159 -0.209650 -1.0\n",
       "463 -0.006007 -1.0\n",
       "\n",
       "[464 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input1=valid_data1\n",
    "input2=valid_data2\n",
    "#input1=train_data1\n",
    "#input2=train_data2\n",
    "# モデルを評価モードに設定\n",
    "model.eval()\n",
    "\n",
    "# 推論\n",
    "with torch.no_grad():\n",
    "    output1, output2 = model(input1, input2)\n",
    "\n",
    "# コサイン類似度の計算\n",
    "cosine_similarity = F.cosine_similarity(output1, output2).numpy()\n",
    "\n",
    "res_df=pd.DataFrame([cosine_similarity,valid_labels.numpy()]).T\n",
    "\n",
    "res_df.sort_values(1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008620689655172414"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
