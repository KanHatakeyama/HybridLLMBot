{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncompletion = openai.ChatCompletion.create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[{\"role\": \"user\", \"content\": \"昔々あるところに\"}],\\n    stream=True,\\n)\\nfor chunk in completion:\\n    next = chunk[\\'choices\\'][0][\\'delta\\'].get(\\'content\\', \\'\\')\\n    print(next, end=\\'\\')\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ライブラリの自動リロード\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import openai\n",
    "from settings.key import GPT_API_KEY\n",
    "openai.api_key = GPT_API_KEY\n",
    "\n",
    "\"\"\"\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"昔々あるところに\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in completion:\n",
    "    next = chunk['choices'][0]['delta'].get('content', '')\n",
    "    print(next, end='')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMSearch.AnswerBot import AnswerBot,parse_answer\n",
    "from settings.key import GPT_API_KEY, DEEPL_API_KEY\n",
    "from LLMSearch.GPTQuery import GPTQuery\n",
    "from LLMSearch.BM25DB import BM25DB\n",
    "\n",
    "#bm=BM25DB(initiate=True)\n",
    "\n",
    "\n",
    "# initiate bot module\n",
    "bot = AnswerBot(query_module=GPTQuery(GPT_API_KEY),\n",
    "                DEEPL_API_KEY=DEEPL_API_KEY,\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/359 [00:39<23:09,  3.98s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/kh/python/2023/20230427rwkvGPT/0614stream.ipynb セル 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bold-ubuntu/media/kh/python/2023/20230427rwkvGPT/0614stream.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m bot\u001b[39m.\u001b[39;49mindex_documents(initiate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/media/kh/python/2023/20230427rwkvGPT/LLMSearch/AnswerBot.py:63\u001b[0m, in \u001b[0;36mAnswerBot.index_documents\u001b[0;34m(self, initiate)\u001b[0m\n\u001b[1;32m     59\u001b[0m path_list \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings[\u001b[39m\"\u001b[39m\u001b[39mdata_path\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/original/**/*.txt\u001b[39m\u001b[39m\"\u001b[39m, recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m tqdm(path_list):\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearcher\u001b[39m.\u001b[39;49madd_text(path)\n",
      "File \u001b[0;32m/media/kh/python/2023/20230427rwkvGPT/LLMSearch/BM25DB.py:59\u001b[0m, in \u001b[0;36mBM25DB.add_text\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     57\u001b[0m chunk_list \u001b[39m=\u001b[39m split_text(text, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_size_limit)\n\u001b[1;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m i, chunk \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(chunk_list):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_record(path, chunk, i)\n",
      "File \u001b[0;32m/media/kh/python/2023/20230427rwkvGPT/LLMSearch/BM25DB.py:39\u001b[0m, in \u001b[0;36mBM25DB.add_record\u001b[0;34m(self, path, text, split_id, commit)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc\u001b[39m.\u001b[39mexecute(\u001b[39m\"\u001b[39m\u001b[39mINSERT INTO docs(content, filepath, number) VALUES(?, ?, ?);\u001b[39m\u001b[39m\"\u001b[39m, (doc_wakati, path, split_id))\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m commit:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommit()\n",
      "File \u001b[0;32m/media/kh/python/2023/20230427rwkvGPT/LLMSearch/BM25DB.py:42\u001b[0m, in \u001b[0;36mBM25DB.commit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcommit\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconn\u001b[39m.\u001b[39;49mcommit()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bot.index_documents(initiate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"先生の業績は?\"\n",
    "query=\"先生の趣味は?\"\n",
    "related_documents=bot.search_related_documents(query, k=20)\n",
    "\n",
    "ans={}\n",
    "ans[\"answer\"]=\"\"\n",
    "ans[\"context\"]=related_documents\n",
    "str_ans=parse_answer(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#related_documentを5こずつに分割\n",
    "related_documents_list=[related_documents[i:i+5] for i in range(0,len(related_documents),5)]\n",
    "related_documents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=bot.ask(query,context_list= related_documents,stream=True)\n",
    "\n",
    "ans=response[\"answer\"]\n",
    "for chunk in ans:\n",
    "    next = chunk['choices'][0]['delta'].get('content', '')\n",
    "    print(next, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
