{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルを自動リロード\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from LLMSearch.ServerEmbedding import ServerEmbedding\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedder=ServerEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vec_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/kh/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/kh/.cache/torch_extensions/py310_cu117/wkv_cuda/build.ninja...\n",
      "Building extension module wkv_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module wkv_cuda...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "RWKV_JIT_ON 0 RWKV_CUDA_ON 1 RESCALE_LAYER 6\n",
      "\n",
      "Loading /media/kh/python/2023/RWKV-4b-Pile-3B-20230228-7963.pth ...\n",
      "Strategy: (total 32+1=33 layers)\n",
      "* cuda [float16, float16], store 33 layers\n",
      "0-cuda-float16-float16 1-cuda-float16-float16 2-cuda-float16-float16 3-cuda-float16-float16 4-cuda-float16-float16 5-cuda-float16-float16 6-cuda-float16-float16 7-cuda-float16-float16 8-cuda-float16-float16 9-cuda-float16-float16 10-cuda-float16-float16 11-cuda-float16-float16 12-cuda-float16-float16 13-cuda-float16-float16 14-cuda-float16-float16 15-cuda-float16-float16 16-cuda-float16-float16 17-cuda-float16-float16 18-cuda-float16-float16 19-cuda-float16-float16 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 25-cuda-float16-float16 26-cuda-float16-float16 27-cuda-float16-float16 28-cuda-float16-float16 29-cuda-float16-float16 30-cuda-float16-float16 31-cuda-float16-float16 32-cuda-float16-float16 \n",
      "emb.weight                        f16      cpu  50277  2560 \n",
      "blocks.0.ln1.weight               f16   cuda:0   2560       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   2560       \n",
      "blocks.0.ln2.weight               f16   cuda:0   2560       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   2560       \n",
      "blocks.0.att.time_decay           f32   cuda:0   2560       \n",
      "blocks.0.att.time_first           f32   cuda:0   2560       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_qq          f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_kk          f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_vv          f16   cuda:0   2560       \n",
      "blocks.0.att.att_mask             f16   cuda:0   1024  1024 \n",
      "blocks.0.att.key.weight           f16   cuda:0   2560  2560 \n",
      "blocks.0.att.value.weight         f16   cuda:0   2560  2560 \n",
      "blocks.0.att.receptance.weight    f16   cuda:0   2560  2560 \n",
      "blocks.0.att.output.weight        f16   cuda:0   2560  2560 \n",
      "blocks.0.att.qq.weight            f16   cuda:0    160  2560 \n",
      "blocks.0.att.kk.weight            f16   cuda:0    160  2560 \n",
      "blocks.0.att.vv.weight            f16   cuda:0    160  2560 \n",
      "blocks.0.att.oo.weight            f16   cuda:0   2560   160 \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   2560       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   2560       \n",
      "blocks.0.ffn.key.weight           f16   cuda:0   2560 10240 \n",
      "blocks.0.ffn.receptance.weight    f16   cuda:0   2560  2560 \n",
      "blocks.0.ffn.value.weight         f16   cuda:0  10240  2560 \n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.31.ln1.weight              f16   cuda:0   2560       \n",
      "blocks.31.ln1.bias                f16   cuda:0   2560       \n",
      "blocks.31.ln2.weight              f16   cuda:0   2560       \n",
      "blocks.31.ln2.bias                f16   cuda:0   2560       \n",
      "blocks.31.att.time_decay          f32   cuda:0   2560       \n",
      "blocks.31.att.time_first          f32   cuda:0   2560       \n",
      "blocks.31.att.time_mix_k          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_v          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_r          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_qq         f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_kk         f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_vv         f16   cuda:0   2560       \n",
      "blocks.31.att.att_mask            f16   cuda:0   1024  1024 \n",
      "blocks.31.att.key.weight          f16   cuda:0   2560  2560 \n",
      "blocks.31.att.value.weight        f16   cuda:0   2560  2560 \n",
      "blocks.31.att.receptance.weight   f16   cuda:0   2560  2560 \n",
      "blocks.31.att.output.weight       f16   cuda:0   2560  2560 \n",
      "blocks.31.att.qq.weight           f16   cuda:0    160  2560 \n",
      "blocks.31.att.kk.weight           f16   cuda:0    160  2560 \n",
      "blocks.31.att.vv.weight           f16   cuda:0    160  2560 \n",
      "blocks.31.att.oo.weight           f16   cuda:0   2560   160 \n",
      "blocks.31.ffn.time_mix_k          f16   cuda:0   2560       \n",
      "blocks.31.ffn.time_mix_r          f16   cuda:0   2560       \n",
      "blocks.31.ffn.key.weight          f16   cuda:0   2560 10240 \n",
      "blocks.31.ffn.receptance.weight   f16   cuda:0   2560  2560 \n",
      "blocks.31.ffn.value.weight        f16   cuda:0  10240  2560 \n",
      "ln_out.weight                     f16   cuda:0   2560       \n",
      "ln_out.bias                       f16   cuda:0   2560       \n",
      "head.weight                       f16   cuda:0   2560 50277 \n",
      "RWKV initiated successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['RWKV_JIT_ON'] = '0'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '1'\n",
    "\n",
    "from LLMSearch.Embedding.VicunaEmbedding import VicunaEmbedding\n",
    "from LLMSearch.Embedding.RWKVEmbedding import RWKVEmbedding\n",
    "vicuna=RWKVEmbedding(model_path=\"/media/kh/python/2023/RWKV-4b-Pile-3B-20230228-7963.pth\",\n",
    "                #strategy=\"\",    \n",
    "                strategy=\"cuda fp16\"\n",
    "                     )\n",
    "#vicuna=VicunaEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/numpy/linalg/linalg.py:2541: RuntimeWarning: overflow encountered in multiply\n",
      "  s = (x.conj() * x).real\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.2308733 ,  0.27107906,  0.3374898 , ...,  0.36548182,\n",
       "       -0.20509568,  0.0929408 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "txt=\"better man\"\n",
    "self=vicuna\n",
    "inp_vec=self.pipeline.encode(txt)\n",
    "out, state = self.model.forward(inp_vec, None)\n",
    "np_state=[i.detach().cpu().numpy() for i in state]\n",
    "\n",
    "#nanとなっているnp_stateを削除\n",
    "np_state=[i for i in np_state if not np.isnan(i).any()]\n",
    "\n",
    "np_state=[i for i in np_state if np.linalg.norm(i, axis=0, keepdims=True)<10**2]\n",
    "print(len(np_state))\n",
    "np_state=np.mean(np_state,axis=0)\n",
    "np_state\n",
    "\n",
    "#norm = np.linalg.norm(np_state, axis=0, keepdims=True)\n",
    "\n",
    "#np_state/norm\n",
    "#np_state=np.mean(np_state,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01252387,  0.01470486,  0.01830735, ...,  0.0198258 ,\n",
       "        -0.01112555,  0.00504163]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vicuna.normalize=True\n",
    "v=vicuna(\"better man\")\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder=vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2560)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "norm = np.linalg.norm(v, axis=1, keepdims=True)\n",
    "\n",
    "(v/norm).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def encode(text):\n",
    "    #v=calc_vec(text,embedder.model,embedder.tokenizer)\n",
    "    v=embedder(text)\n",
    "    v=v/np.linalg.norm(v, axis=1, keepdims=True)\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/numpy/linalg/linalg.py:2541: RuntimeWarning: overflow encountered in multiply\n",
      "  s = (x.conj() * x).real\n"
     ]
    }
   ],
   "source": [
    "text_list=[\n",
    "\"吾輩は猫である\",\n",
    "\"汝の名は女だ\",\n",
    "\"I am a cat\",\n",
    "\"ピペットで試薬を三回分取した\",\n",
    "\"アセトンは有機溶媒である\",\n",
    "\"非プロトン性溶媒として､THF､トルエンなどが挙げられる\",\n",
    "\"トルエンをこぼしてしまいました\",\n",
    "\"私は猫です\",\n",
    "\"私は犬です\",\n",
    "\"日本的霊性は，鎌倉時代に禅と浄土系思想によって初めて明白に顕現し，その霊性的自覚が現在に及ぶと述べる．\",\n",
    "]\n",
    "\n",
    "text_vec_list=[encode(text) for text in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text=\"猫は嫌いです\"\n",
    "target_text=\"猫の名前は?\"\n",
    "target_text=\"what is the cat name\"\n",
    "target_vec=encode(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a cat [[0.71107215]]\n",
      "私は犬です [[0.6684967]]\n",
      "私は猫です [[0.6530493]]\n",
      "汝の名は女だ [[0.5569266]]\n",
      "トルエンをこぼしてしまいました [[0.5476856]]\n",
      "非プロトン性溶媒として､THF､トルエンなどが挙げられる [[0.5356035]]\n",
      "アセトンは有機溶媒である [[0.5138507]]\n",
      "ピペットで試薬を三回分取した [[0.51057684]]\n",
      "吾輩は猫である [[0.5099911]]\n",
      "日本的霊性は，鎌倉時代に禅と浄土系思想によって初めて明白に顕現し，その霊性的自覚が現在に及ぶと述べる． [[0.50985444]]\n"
     ]
    }
   ],
   "source": [
    "sim_list=[]\n",
    "for text,vec in zip(text_list,text_vec_list):\n",
    "    #target_vec=target_vec.reshape(1,-1)\n",
    "    #vec=vec.reshape(1,-1)\n",
    "    sim_list.append((text,cosine_similarity(target_vec,vec)))\n",
    "\n",
    "#コサイン類似度でソート\n",
    "sim_list.sort(key=lambda x:x[1],reverse=True)\n",
    "for text,sim in sim_list:\n",
    "    print(text,sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15015 [00:00<?, ?it/s]/home/kh/anaconda3/envs/lora/lib/python3.10/site-packages/numpy/linalg/linalg.py:2541: RuntimeWarning: overflow encountered in multiply\n",
      "  s = (x.conj() * x).real\n",
      "  3%|▎         | 476/15015 [00:42<30:16,  8.00it/s]"
     ]
    }
   ],
   "source": [
    "from LLMSearch.Siamese.DictEmbedder import DictEmbedder\n",
    "from tqdm import tqdm\n",
    "dict_embedder=DictEmbedder(\"develop/databricks-dolly-15k-ja-vec.bin\",embedder,init=False)\n",
    "\n",
    "bricks_dict=json.load(open(\"develop/databricks-dolly-15k-ja.json\"))\n",
    "#vec_dict_path=\"develop/databricks-dolly-15k-ja-vec.bin\"\n",
    "\n",
    "for brick in tqdm(bricks_dict):\n",
    "    instruction=brick[\"instruction\"]\n",
    "    output=brick[\"output\"]\n",
    "    v=dict_embedder(instruction)\n",
    "    v=dict_embedder(output)\n",
    "    #print(instruction)\n",
    "    #try:\n",
    "    #    if instruction not in vec_dict:\n",
    "    #        vec_dict[instruction]=embedder(instruction)\n",
    "    #    if output not in vec_dict:\n",
    "    #        vec_dict[output]=embedder(output)\n",
    "    #except:\n",
    "    #    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
