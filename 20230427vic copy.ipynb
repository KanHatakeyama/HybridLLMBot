{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe036fe070d4e70826b4acf3cd8a743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"eachadea/vicuna-13b-1.1\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"eachadea/vicuna-13b-1.1\",device_map = 'auto')\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"elinas/vicuna-13b-4bit\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"elinas/vicuna-13b-4bit\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AlekseyKorshuk/vicuna-7b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"AlekseyKorshuk/vicuna-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def calc_vec(input_text, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, output_hidden_states=True)\n",
    "\n",
    "    #list形式でtensorが入っているoutputsを1次元のnumpyに変換\n",
    "    vec_list=[]\n",
    "    for v in outputs[-1]:\n",
    "        mean_v=v.mean(axis=1)\n",
    "        vec_list.append(mean_v.numpy().flatten())\n",
    "\n",
    "    vec=np.array(vec_list).flatten()\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 吾輩は猫である\n",
      "0.988 私は猫です\n",
      "0.986 私は犬です\n",
      "0.984 汝の名は女だ\n",
      "0.964 I am a cat\n",
      "0.960 アセトンは有機溶媒である\n",
      "0.959 トルエンをこぼしてしまいました\n",
      "0.947 ピペットで試薬を三回分取した\n",
      "0.871 非プロトン性溶媒として､THF､トルエンなどが挙げられる\n",
      "0.654 日本的霊性は，鎌倉時代に禅と浄土系思想によって初めて明白に顕現し，その霊性的自覚が現在に及ぶと述べる．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "text_list=[\n",
    "\"吾輩は猫である\",\n",
    "\"汝の名は女だ\",\n",
    "\"I am a cat\",\n",
    "\"ピペットで試薬を三回分取した\",\n",
    "\"アセトンは有機溶媒である\",\n",
    "\"非プロトン性溶媒として､THF､トルエンなどが挙げられる\",\n",
    "\"トルエンをこぼしてしまいました\",\n",
    "\"私は猫です\",\n",
    "\"私は犬です\",\n",
    "\"日本的霊性は，鎌倉時代に禅と浄土系思想によって初めて明白に顕現し，その霊性的自覚が現在に及ぶと述べる．\",\n",
    "]\n",
    "\n",
    "\n",
    "vec_list=[calc_vec(i,model,tokenizer) for i in tqdm(text_list)]\n",
    "\n",
    "\n",
    "target_vec=vec_list[0]\n",
    "\n",
    "\n",
    "from scipy import spatial\n",
    "def cos_sim(a, b):\n",
    "    return 1 - spatial.distance.cosine(a, b)\n",
    "\n",
    "\n",
    "cos_sim_list=[cos_sim(target_vec,i) for i in vec_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 吾輩は猫である\n",
      "0.988 私は猫です\n",
      "0.986 私は犬です\n",
      "0.984 汝の名は女だ\n",
      "0.964 I am a cat\n",
      "0.960 アセトンは有機溶媒である\n",
      "0.959 トルエンをこぼしてしまいました\n",
      "0.947 ピペットで試薬を三回分取した\n",
      "0.871 非プロトン性溶媒として､THF､トルエンなどが挙げられる\n",
      "0.654 日本的霊性は，鎌倉時代に禅と浄土系思想によって初めて明白に顕現し，その霊性的自覚が現在に及ぶと述べる．\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(cos_sim_list)[::-1]:\n",
    "    print(\"{:.3f}\".format(cos_sim_list[i]),text_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
