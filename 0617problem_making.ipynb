{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#ライブラリの自動リロード\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from settings.key import GPT_API_KEY\n",
    "openai.api_key = GPT_API_KEY\n",
    "from LLMSearch.AutoDataset.GPTQuestions import gpt_function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmplq527ht7\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmplq527ht7/_remote_module_non_scriptable.py\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a47591db8544c99835891b5c45a505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from LLMSearch.AnswerBot import AnswerBot,parse_answer\n",
    "from settings.key import GPT_API_KEY, DEEPL_API_KEY\n",
    "from LLMSearch.GPTQuery import GPTQuery\n",
    "from LLMSearch.BM25DB import BM25DB\n",
    "from LLMSearch.SQLTextDB import SQLTextDB\n",
    "from LLMSearch.Embedding.SBERTFineTuneEmbedding import SBERTFineTuneEmbedding\n",
    "from LLMSearch.VectorSearcher import VectorSearcher\n",
    "\n",
    "embedder=SBERTFineTuneEmbedding()\n",
    "searcher=VectorSearcher(embedder,chunk_size_limit=500)\n",
    "\n",
    "\n",
    "#bm=BM25DB(initiate=True)\n",
    "#searcher=SQLTextDB()\n",
    "\n",
    "# initiate bot module\n",
    "bot1 = AnswerBot(query_module=GPTQuery(GPT_API_KEY),\n",
    "                searcher=searcher,\n",
    "                DEEPL_API_KEY=DEEPL_API_KEY,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMSearch.DocSplitter import split_text,remove_stopwords\n",
    "path=bot1.searcher.path_list[-1]\n",
    "path_list=list(set(bot1.searcher.path_list))\n",
    "path_list=[path for path in path_list if path.find(\"koko\")==-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list=path_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q1': 'ポリマーの結晶性が減少するのは何が原因ですか？',\n",
       " 'q2': '高いシンジオタクチック立体規則性を持つ主鎖を持つポリマーの合成には何を使用しましたか？',\n",
       " 'q3': 'くし状ポリマーを合成するために使用した触媒は何ですか？',\n",
       " 'q4': 'グラフト共重合体を合成するために使用した触媒は何ですか？',\n",
       " 'q5': 'マクロモノマーとスチレンの共重合を行うために使用した触媒は何ですか？',\n",
       " 'q6': '3元共重合体の合成にどのような手法を使用しましたか？',\n",
       " 'q7': 'ABAブロック共重合体の合成にどのような手法を使用しましたか？',\n",
       " 'q8': 'メタロセン触媒はどのような重合の可能性を与えますか？'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import shutil\n",
    "count=0\n",
    "for path in path_list:\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "    chunk_list = split_text(text, bot1.searcher.chunk_size_limit)\n",
    "\n",
    "    # remove stopwords\n",
    "    chunk_list = [remove_stopwords(chunk) for chunk in chunk_list]\n",
    "\n",
    "\n",
    "    for text in chunk_list:\n",
    "        questions=gpt_function_call(text)\n",
    "\n",
    "        out_path=\"UserData/meta/qa/qa.txt\"\n",
    "        for q in questions:\n",
    "            with open(out_path, 'a') as f:\n",
    "                f.write(path)\n",
    "                f.write(\"|||||\")\n",
    "                f.write(questions[q])\n",
    "                f.write(\"|||||\")\n",
    "                f.write(text)\n",
    "                f.write(\"\\n\")\n",
    "        print(questions)\n",
    "    #コピーを作成してバックアップ\n",
    "    shutil.copyfile(out_path, f\"UserData/meta/qa/qa_backup{count}.txt\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UserData/meta/qa/qa_backup.txt'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
